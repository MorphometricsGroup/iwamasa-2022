{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a7f4e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "import joblib\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as albu\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(\n",
    "            self, \n",
    "            data_dir=None,\n",
    "            augmentation=None, \n",
    "            preprocessing=None,):\n",
    "        self.image_paths = [p for p in glob(str(data_dir / '*.jpg'))]\n",
    "        self.mask_paths = [p.split('.jpg')[0] + '.npy' for p in self.image_paths]      \n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.image_paths[idx])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = np.load(self.mask_paths[idx])\n",
    "        mask = np.expand_dims(mask, axis=-1)\n",
    "        \n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "            \n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    \"\"\"Construct preprocessing t      ransform\n",
    "    \n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function \n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "    \n",
    "    \"\"\"\n",
    "    _transform = [\n",
    "        albu.Lambda(image=preprocessing_fn),\n",
    "        albu.Lambda(image=to_tensor),\n",
    "    ]\n",
    "    return albu.Compose(_transform)\n",
    "\n",
    "\n",
    "def detect_green_color(img):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    hsv_min = np.array([30, 64, 0])\n",
    "    hsv_max = np.array([90, 255, 255])\n",
    "    mask = cv2.inRange(hsv, hsv_min, hsv_max)\n",
    "    masked_img = cv2.bitwise_and(img, img, mask=mask)\n",
    "    return mask, masked_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01e1afc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a547de8d097a4e6eaf274ec85d0a897d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BASE_DIR = '../'\n",
    "INFERENCE_PATH = os.path.join(BASE_DIR, 'data/processed/segment-non-treated-dataset')\n",
    "IMAGE_DIR = os.path.join(BASE_DIR,  'data/interm/non-treated-dataset')\n",
    "\n",
    "ENCODER = 'resnet18'\n",
    "DECODER = 'unet'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "ACTIVATION = 'sigmoid'\n",
    "DEVICE = 'cuda'\n",
    "crop_size = 512\n",
    "buffer_size = 32\n",
    "patch_size = crop_size - 2 * buffer_size\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(\n",
    "    ENCODER, \n",
    "    ENCODER_WEIGHTS\n",
    ")\n",
    "preprocessing = get_preprocessing(preprocessing_fn)\n",
    "best_model = torch.load(\n",
    "    os.path.join(BASE_DIR , f'models/gray_{ENCODER}_{DECODER}.pth')\n",
    ")\n",
    "\n",
    "image_paths = glob(os.path.join(IMAGE_DIR, '*'))\n",
    "count = 0\n",
    "\n",
    "for i, path in tqdm(enumerate(image_paths), total=len(image_paths)):\n",
    "    file_name = path.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    # detect grean-area\n",
    "    im = cv2.imread(path)\n",
    "    contours, hierarchy = cv2.findContours(\n",
    "        detect_green_color(im)[0], \n",
    "        cv2.RETR_TREE, \n",
    "        cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "    max_contours = max(contours, key=lambda x: cv2.contourArea(x))\n",
    "    mask = cv2.drawContours(\n",
    "        np.zeros_like(im[:,:,0]),\n",
    "        [max_contours],\n",
    "        -1,\n",
    "        color=255,\n",
    "        thickness=-1\n",
    "    )\n",
    "    im = cv2.imread(path, 0)\n",
    "    im = np.where(mask==255, 255-im, 255)\n",
    "    \n",
    "    im = np.expand_dims(im, axis=-1)\n",
    "    im = np.repeat(im, 3, axis=-1)\n",
    "    new_shape = [-(-im.shape[i]//patch_size)*patch_size + 2*buffer_size  for i in [0, 1]] + [3]\n",
    "    reshape_im = np.ones(new_shape, dtype=np.uint8) * 255\n",
    "    reshape_im[buffer_size:im.shape[0]+buffer_size, buffer_size:im.shape[1]+buffer_size, :] = im\n",
    "\n",
    "    output_im = np.zeros((new_shape[0], new_shape[1]), dtype=np.float32)\n",
    "    for h_i, h in enumerate(range(buffer_size, new_shape[0]-buffer_size, patch_size)):\n",
    "        for w_i, w in enumerate(range(buffer_size, new_shape[1]-buffer_size, patch_size)):\n",
    "            h -= buffer_size\n",
    "            w -= buffer_size\n",
    "            tmp_im = reshape_im[h:h+crop_size, w:w+crop_size, :]\n",
    "            if reshape_im.mean() > 0:\n",
    "                tmp_im = preprocessing(image=tmp_im)\n",
    "                x_tensor = torch.from_numpy(tmp_im['image']).to(DEVICE).unsqueeze(0)\n",
    "                tmp_output_im = best_model.predict(x_tensor).squeeze().cpu().numpy()\n",
    "                h += buffer_size\n",
    "                w += buffer_size\n",
    "                output_im[h:h+patch_size, w:w+patch_size] = tmp_output_im[buffer_size:-buffer_size, buffer_size:-buffer_size]\n",
    "    output_im = ((output_im)*255).astype(np.uint8)\n",
    "    cv2.imwrite(os.path.join(INFERENCE_PATH, (file_name+'.png')), im)\n",
    "    cv2.imwrite(os.path.join(INFERENCE_PATH, ('vein_'+file_name+'.png')), output_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d12cc315",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Image data of dtype object cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_739/701352575.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/_api/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m                 \u001b[0;34m\"parameter will become keyword-only %(removal)s.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                 name=name, obj_type=f\"parameter of {func.__name__}()\")\n\u001b[0;32m--> 456\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;31m# Don't modify *func*'s signature, as boilerplate.py needs it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2645\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2646\u001b[0m         \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2647\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m   2648\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2649\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/_api/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m                 \u001b[0;34m\"parameter will become keyword-only %(removal)s.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                 name=name, obj_type=f\"parameter of {func.__name__}()\")\n\u001b[0;32m--> 456\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;31m# Don't modify *func*'s signature, as boilerplate.py needs it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1412\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5486\u001b[0m                               **kwargs)\n\u001b[1;32m   5487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5488\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5489\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[1;32m    706\u001b[0m             raise TypeError(\"Image data of dtype {} cannot be converted to \"\n\u001b[0;32m--> 707\u001b[0;31m                             \"float\".format(self._A.dtype))\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Image data of dtype object cannot be converted to float"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = '../data/processed/non-treated-dataset/vein_Zelkova_serrata_0.png'\n",
    "im = cv2.imread(path, 0)\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.imshow(im, cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
